{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W23LcRScf6-S"
      },
      "source": [
        "# GPT Chat Completion Lab\n",
        "\n",
        "Welcome! In this mini-lab we will explore how to build a playful yet practical chat assistant using the GPT 5 models. The goal is to make the workflow clear enough for beginners while giving you a template you can adapt for your usecases.\n",
        "\n",
        "Objectives:\n",
        "- Build a basic GPT-powered chat assistant  \n",
        "- Adjust assistant behavior using system prompts  \n",
        "- Build a simple Gradio UI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i55vtKX9f6-U"
      },
      "source": [
        "## Game Plan\n",
        "- **Context:** We are using Google Colab, so everything happens in the cloud.\n",
        "- **Model:** `gpt-5-nano` keeps responses smart while staying cost-efficient.\n",
        "- **Secret management:** We read the API key from the Colab secret named `OpenAI_API_Key`.\n",
        "- **Flow:** install the SDK â†’ load the key securely â†’ define a helper function â†’ experiment with prompts.\n",
        "- **Stretch idea:** tweak the conversation style and system prompt with your own ideas.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "from openai import OpenAI\n",
        "import gradio as gr\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "MODEL=\"gpt-5-nano\""
      ],
      "metadata": {
        "id": "6V2GzCq47uqQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90urDtAwf6-V"
      },
      "source": [
        "## Load Secrets (No Hard-Coding!)\n",
        "Colab lets us keep keys in the `userdata` vault. Make sure your workspace already stores `OpenAI_API_Key`; otherwise run `userdata.set_secret` once (never share the value).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bTQdB0Yvf6-V"
      },
      "outputs": [],
      "source": [
        "os.environ['OPENAI_API_KEY'] = userdata.get('OpenAI_API_Key')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou_qMNtYf6-V"
      },
      "source": [
        "## Wrap the GPT Client\n",
        "We use the official `openai` package. The helper below:\n",
        "1. Initializes a single `OpenAI` client.\n",
        "2. Accepts a system message and a list of user turns.\n",
        "3. Returns the model reply plus token usage so we can discuss cost control.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI()\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=MODEL,\n",
        "    input=\"Write a one-sentence bedtime story about a unicorn.\"\n",
        ")\n",
        "\n",
        "response"
      ],
      "metadata": {
        "id": "wXdFkxJ3iugG",
        "outputId": "16357e1d-358f-4f3f-c209-d5adc101be20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Response(id='resp_028e2abd172cb2b600691c927aef3c8192add7080f133ab320', created_at=1763480186.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5-nano-2025-08-07', object='response', output=[ResponseReasoningItem(id='rs_028e2abd172cb2b600691c927c60708192ba247f85cead9c01', summary=[], type='reasoning', content=None, encrypted_content=None, status=None), ResponseOutputMessage(id='msg_028e2abd172cb2b600691c928091f081928834e28cef38f235', content=[ResponseOutputText(annotations=[], text='Under a silver moon, a gentle unicorn trotted through the sleeping meadow and sang a lullaby of starlight, whispering good-night to the sleepy flowers until the whole world drifted into a peaceful dream.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort='medium', generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=17, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=433, output_tokens_details=OutputTokensDetails(reasoning_tokens=384), total_tokens=450), user=None, billing={'payer': 'developer'}, prompt_cache_retention=None, store=True)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.usage.output_tokens"
      ],
      "metadata": {
        "id": "xh9yN9STz4nr",
        "outputId": "75e7157c-a0e5-4ffc-b222-706e76518254",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "433"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's extract the reply part only:"
      ],
      "metadata": {
        "id": "e6a9hT4ckUH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.output_text)"
      ],
      "metadata": {
        "id": "EDGGZasgjiQe",
        "outputId": "bb428704-6551-40ff-8555-8eddf7d70102",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Under a silver moon, a gentle unicorn trotted through the sleeping meadow and sang a lullaby of starlight, whispering good-night to the sleepy flowers until the whole world drifted into a peaceful dream.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## System Instructions\n",
        "Formerly known as system/developer prompt. The instructions parameter sets high-level guidance for how the model should behaveâ€”its tone, goals, and styleâ€”while message roles give more specific, task-level directions.\n"
      ],
      "metadata": {
        "id": "dnc_cKFBpPy-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/soltaniehha/Business-Analytics-Toolbox/master/docs/images/Prof-Owl-1.png\"\n",
        "     width=\"300\">\n"
      ],
      "metadata": {
        "id": "3cgtRdAerkMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instructions = \"You are Professor Owl, a wise but approachable teacher. Give clear, simple explanations and gently guide students without sounding formal.\"\n",
        "input = \"why do data analysts prefer Python or SQL instead of Excel for big datasets?\"\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=MODEL,\n",
        "    instructions=instructions,   # Formerly known as system prompt\n",
        "    input=input,                 # User prompt\n",
        "    text={ \"verbosity\": \"low\" }  # Low: short, concise outputs â€” High: detailed explanations or big refactors\n",
        ")\n",
        "\n",
        "Markdown(response.output_text)"
      ],
      "metadata": {
        "id": "jQWnIpPglvV6",
        "outputId": "17dc39ba-bd23-4052-96b8-d01a43b327d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Great question! Hereâ€™s the short answer: for big datasets, Python or SQL are preferred because they scale, automate, and keep things reproducible. Excel just isnâ€™t built for that scale.\n\nKey reasons in simple terms:\n- Scale and performance: Excel has row limits and memory constraints. SQL databases and Python data tools are designed to process large data efficiently.\n- Data integrity and governance: Databases enforce rules and keep data in a central, auditable place. Excel files can get out of sync and messy.\n- Reproducibility and automation: SQL scripts and Python notebooks can be versioned, shared, and rerun automatically. Excel steps are often manual and error-prone.\n- Transformation power: SQL shines at filtering, joining, and aggregating big tables. Python (pandas, Dask) handles complex wrangling and later modeling.\n- Collaboration: Code in SQL/Python + version control works well for teams. Excel files are harder to track changes in.\n- Ecosystem: Rich libraries, connectors, and tooling exist for SQL and Python (data cleaning, ML, dashboards). Excel is more limited in these areas for big data.\n\nWhen Excel is fine:\n- Small datasets (well under Excelâ€™s limits).\n- Quick ad-hoc checks, pivots, or lightweight dashboards.\n- Prototyping or learning, before moving data to SQL/Python workflows.\n\nQuick guideline:\n- Extract and summarize large data with SQL.\n- Do cleaning, feature engineering, and modeling with Python.\n- Use Excel only for small, quick inspections or presentations.\n\nIf you want, tell me about your data size and tools you have, and Iâ€™ll suggest a simple start plan."
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chat History"
      ],
      "metadata": {
        "id": "Y-aeunFKv32y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep history\n",
        "history = [{\"role\": \"developer\", \"content\": instructions}]\n",
        "\n",
        "def chat(message):\n",
        "    history.append({\"role\": \"user\", \"content\": message})  # Add the new user message to history\n",
        "\n",
        "    # Send entire history to the model\n",
        "    response = client.responses.create(\n",
        "        model=MODEL,\n",
        "        input=history,\n",
        "        text={ \"verbosity\": \"low\" }\n",
        "    )\n",
        "\n",
        "    # Add model response to history\n",
        "    history.append({\"role\": \"assistant\", \"content\": response.output_text})\n",
        "\n",
        "    return response.output_text"
      ],
      "metadata": {
        "id": "VjSQ771duhdJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(chat(input))"
      ],
      "metadata": {
        "id": "JloK9KRtujRr",
        "outputId": "4687538b-16ef-4c05-8804-2e4d9f14dfb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Short answer: for big datasets, Python and SQL are more scalable, faster, and better for reproducible analyses. Excel just isnâ€™t built for that scale.\n\nKey reasons:\n\n- Size and memory\n  - Excel has a hard size limit and can slow to a crawl with large files.\n  - SQL databases store data on disk and use indexing; Python can stream data or use out-of-core tools when needed.\n\n- Performance and operations\n  - SQL excels at fast, set-based joins, aggregations, and filtering on huge tables.\n  - Python (with pandas) is great for flexible cleaning and feature engineering but can be memory-heavy; itâ€™s often used with chunking or on machines with enough RAM.\n\n- Reproducibility and automation\n  - SQL scripts and Python notebooks can be versioned, tested, and automated (pipelines, schedulers).\n  - Excel files are harder to track changes in and less friendly to automated workflows.\n\n- Data integrity and multi-user work\n  - SQL databases support transactions, constraints, and concurrent access.\n  - Excel is prone to human errors and file conflicts when multiple people edit the same file.\n\n- Advanced analytics and tooling\n  - Python offers ML, statistical modeling, APIs, and visualization libraries.\n  - Excel provides quick ad-hoc calculations but lacks scalable analytics and modeling capabilities.\n\n- Data wrangling at scale\n  - SQL is ideal for extracting and consolidating data from many tables.\n  - Python is great for deeper cleaning, feature engineering, and modeling after data is pulled.\n\nWhen to use Excel instead\n- For small, simple datasets and quick, human-focused analysis.\n- For business users who need to do simple calculations or pivot tables without coding.\n\nBottom line: big datasets benefit from SQL for data retrieval/aggregation and Python for deeper analysis and modeling, while Excel is best kept for small, quick explorations."
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat(\"Please highlight the most important point\")"
      ],
      "metadata": {
        "id": "4dPpqHsRwGfo",
        "outputId": "27e15f94-ceed-438f-c5f9-79b411b2b9f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Big datasets require scalable toolsâ€”SQL for fast, set-based retrieval/aggregation in a database, and Python for flexible analysis; Excel isnâ€™t designed to handle large data.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history"
      ],
      "metadata": {
        "id": "SLIJdBtjuk-9",
        "outputId": "e88b3886-ac19-4337-e6d6-ada655e57f24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'developer',\n",
              "  'content': 'You are Professor Owl, a wise but approachable teacher. Give clear, simple explanations and gently guide students without sounding formal.'},\n",
              " {'role': 'user',\n",
              "  'content': 'why do data analysts prefer Python or SQL instead of Excel for big datasets?'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Short answer: for big datasets, Python and SQL are more scalable, faster, and better for reproducible analyses. Excel just isnâ€™t built for that scale.\\n\\nKey reasons:\\n\\n- Size and memory\\n  - Excel has a hard size limit and can slow to a crawl with large files.\\n  - SQL databases store data on disk and use indexing; Python can stream data or use out-of-core tools when needed.\\n\\n- Performance and operations\\n  - SQL excels at fast, set-based joins, aggregations, and filtering on huge tables.\\n  - Python (with pandas) is great for flexible cleaning and feature engineering but can be memory-heavy; itâ€™s often used with chunking or on machines with enough RAM.\\n\\n- Reproducibility and automation\\n  - SQL scripts and Python notebooks can be versioned, tested, and automated (pipelines, schedulers).\\n  - Excel files are harder to track changes in and less friendly to automated workflows.\\n\\n- Data integrity and multi-user work\\n  - SQL databases support transactions, constraints, and concurrent access.\\n  - Excel is prone to human errors and file conflicts when multiple people edit the same file.\\n\\n- Advanced analytics and tooling\\n  - Python offers ML, statistical modeling, APIs, and visualization libraries.\\n  - Excel provides quick ad-hoc calculations but lacks scalable analytics and modeling capabilities.\\n\\n- Data wrangling at scale\\n  - SQL is ideal for extracting and consolidating data from many tables.\\n  - Python is great for deeper cleaning, feature engineering, and modeling after data is pulled.\\n\\nWhen to use Excel instead\\n- For small, simple datasets and quick, human-focused analysis.\\n- For business users who need to do simple calculations or pivot tables without coding.\\n\\nBottom line: big datasets benefit from SQL for data retrieval/aggregation and Python for deeper analysis and modeling, while Excel is best kept for small, quick explorations.'},\n",
              " {'role': 'user', 'content': 'Please highlight the most important point'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Big datasets require scalable toolsâ€”SQL for fast, set-based retrieval/aggregation in a database, and Python for flexible analysis; Excel isnâ€™t designed to handle large data.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chatbot\n",
        "Using `Gradio` to build a chatbot that we control its workflow."
      ],
      "metadata": {
        "id": "YhN0hJx-wjzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instructions = \"You are Professor Owl, a wise but friendly teacher of Business Analytics. Explain concepts clearly and simply, using gentle guidance.\"\n",
        "\n",
        "def respond(message, history):\n",
        "    messages = [{\"role\": \"developer\", \"content\": instructions}]\n",
        "    messages.extend({\"role\": m[\"role\"], \"content\": m[\"content\"]} for m in history)\n",
        "    messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "\n",
        "    response = client.responses.create(\n",
        "        model=MODEL,\n",
        "        input=messages,\n",
        "        text={\"verbosity\": \"low\"}\n",
        "    )\n",
        "    return response.output_text\n",
        "\n",
        "demo = gr.ChatInterface(\n",
        "    respond,\n",
        "    type=\"messages\",\n",
        "    title=\"ðŸ¦‰ Professor Owl â€“ Business Analytics Helper\",\n",
        "    description=\"Ask Professor Owl anything data analytics!\"\n",
        ")\n",
        "\n",
        "demo.launch(share=True)  # Add debug=True to debug, if needed"
      ],
      "metadata": {
        "id": "lQtzyh2Exyo1",
        "outputId": "1d307e2f-852f-4e70-8c9a-18c05f8e51d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8135e1dcc538abb267.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8135e1dcc538abb267.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hfh6W_6f6-W"
      },
      "source": [
        "## Your Turn\n",
        "Plug in your own scenario: Rephrase the instructions to shift tone/guidelines.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcHECt7Uf6-W"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}